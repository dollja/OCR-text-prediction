{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Q0ji4Sx3nG2"
   },
   "source": [
    "#Setup and Installation to run Yolov4\n",
    "\n",
    "Following cell will clone darknet from AlexeyAB's famous repository and we will be adjusting the Makefile to enable OPENCV and GPU for darknet and then build darknet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXaZg15vENFH",
    "outputId": "5a876ac7-bdee-4c38-f704-cf06dd53a596"
   },
   "outputs": [],
   "source": [
    "# clone darknet repository\n",
    "!git clone https://github.com/AlexeyAB/darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJGjzPlX4F-7",
    "outputId": "7dbef9df-d4c2-4519-a4c6-1f0ee561cc9c"
   },
   "outputs": [],
   "source": [
    "# change makefile to have GPU and OPENCV enabled\n",
    "%cd darknet\n",
    "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
    "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
    "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
    "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lw-EzxOD4JnY",
    "outputId": "0d1793bb-1dfc-4813-ce13-f8c485c6fbb8"
   },
   "outputs": [],
   "source": [
    "# verify CUDA\n",
    "!/usr/local/cuda/bin/nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NgvJgWDR4M3g",
    "outputId": "b6dbb465-e7ab-47f4-b6ff-a7f935c68a70"
   },
   "outputs": [],
   "source": [
    "# make darknet (builds darknet so that you can then use the darknet executable file to run or train object detectors)\n",
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ls6Kk7kp4Wbq"
   },
   "source": [
    "\n",
    "#Download pre-trained YOLOv4 weights\n",
    "\n",
    "YOLOv4 has been trained already on the coco dataset which has 80 classes that it can predict. We will take these pretrained weights to see how it gives result on some of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFcjfSBs4l_s",
    "outputId": "de37c8e2-222d-4557-bc63-97aa16416bd9"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nzPDox6MJsA"
   },
   "source": [
    "## Display functions to display the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IcW1SFsXL-ts"
   },
   "outputs": [],
   "source": [
    "def imShow(path):\n",
    "  import cv2\n",
    "  import matplotlib.pyplot as plt\n",
    "  %matplotlib inline\n",
    "\n",
    "  image = cv2.imread(path)\n",
    "  height, width = image.shape[:2]\n",
    "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(18, 10)\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TQWPftvMcbk"
   },
   "source": [
    "#### Darknet folder provides some of the images in the data subfolder and we will be using the same image to predict on the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kevBTRzYMbMp",
    "outputId": "4881ebc5-26dc-4f50-b4d2-0c0c25482bd7"
   },
   "outputs": [],
   "source": [
    "# run darknet detection on test images\n",
    "!./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights data/person.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJabQX1DNv79"
   },
   "source": [
    "### Displaying image using our display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "r2TyFnf3MxAM",
    "outputId": "028e9614-4020-4148-8947-a82bece574e0"
   },
   "outputs": [],
   "source": [
    "imShow('predictions.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpyyEfpGNIYA"
   },
   "source": [
    "# Using Yolov4 for detecting different classes in invoice\n",
    "\n",
    "We will create our own custom YOLOv4 object detector to recognize Invoice number,Date and Amount from the Invoice! \n",
    "\n",
    "We will be needing following things to create our custom object detector:\n",
    "\n",
    "*   Labeled Custom Dataset\n",
    "*   Custom .cfg file\n",
    "*   obj.data and obj.names files\n",
    "*   train.txt file and test.txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgnBOdkQJse8"
   },
   "source": [
    "# Step 1: Data collection and Labeling with LabelImg\n",
    "To create a custom object detector we need a good dataset of images and labels for better training of the model so we will label our images using annotation tools LabelImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LT0_mjeKB08"
   },
   "source": [
    "Now  we have a folder as Invoice_pro having subfolder as obj which indicate train dataset and test which indicate validation dataset. Hence we will be converting it into zip file and uploading it in data subfolder of darknet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ew11T1VgPSVX"
   },
   "source": [
    "Unzip the datasets and their contents so that they can be seen as a folder in /darknet/data/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQM1MSGEPPbT",
    "outputId": "b949a775-79f4-459c-ace9-d6078cbf046a"
   },
   "outputs": [],
   "source": [
    "!unzip /content/darknet/data/obj.zip  -d /content/darknet/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CivqIKjTPlLC",
    "outputId": "38f38ac1-5d51-4831-a6a3-fa5ddaa8ffe0"
   },
   "outputs": [],
   "source": [
    "!unzip /content/darknet/data/test.zip  -d /content/darknet/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hxWJ7uOun7S"
   },
   "source": [
    "# Step 2: Configuring Files for Training\n",
    "This step involves configuring custom .cfg, obj.data, obj.names, train.txt and test.txt files.\n",
    "\n",
    "It is important to configure all these files without any typos as small errors can cause major problems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lbh6XBuu8pM6"
   },
   "source": [
    "# 1) Config File\n",
    "\n",
    "Now you need to edit yolov4-custom.cfg to fit your needs based on your object detector. \n",
    "\n",
    "First download yolov4-custom.cfg from path /darknet/cfg/yolov4-custom.cfg and change following parameters.\n",
    "\n",
    "\n",
    "\n",
    " **batch = 64** and **subdivisions = 16** gives best results but if you run into any issues then make subdivisions to 32\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Configuring all the needed variables based on class\n",
    "\n",
    "width = 416\n",
    "\n",
    "height = 416\n",
    "\n",
    "*(these can be any multiple of 32, 416 is standard, improvement in the results can happen if we increase the size of the image but will slow down training)*\n",
    "\n",
    "max_batches = (# of classes) * 2000\n",
    "\n",
    "*(But it shouldnt be less than 6000 so if you are training for 1, 2, or 3 classes it will be 6000, however detector for 5 classes would have max_batches=10000)*\n",
    "\n",
    "steps = (80% of max_batches), (90% of max_batches)\n",
    "\n",
    "*(If your max_batches = 10000, then steps = 8000, 9000*)\n",
    "\n",
    "filters = (# of classes + 5) * 3\n",
    "\n",
    "*(If you are training for one class then your filters = 18, but if you are training for 4 classes then your filters = 27)*\n",
    "\n",
    "Change the name to yolov4-obj.cfg and now upload at the same place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03b-Kgam9Esp"
   },
   "source": [
    "# 2) obj.names and obj.data \n",
    "\n",
    "Create a new file called **obj.names** where you will have one class name per line in the same order as your classes.txt from the dataset generation step.\n",
    "\n",
    "\n",
    " ![objnames.PNG](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOEAAABiCAYAAACml7QMAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAAw5SURBVHhe7Z1LdxNHFsf1RTIQIwtbgB0exoYEQnASHhMgPHzGYB62MUg2yZw5Z2Y3ZyaTxwwMMLblfAo2PsGfIRsvbL4AK2fjLGYxMxt2NXVvV7Wqq6ullrrktqW/zvkdpKru6se5P93qqpIpfP37BZGWJ19VxcJCRVSqc2Lu0Yy4dOkzUezfJw4O9ImBwQMAdBUU1xTfFy6Oc7xT3FP8kwcuP9oltYRffT0vFp5UxPzCY/G48lDMPpwWh48MiNLB950XAEA3QPFNcU7xTnFP8U8ekA8uT9ohtYT1LPhIfivMisuXkQVBb0BxflH2+ijuKf59Z8NUEpL1dFCdBadn7onh4UOiv7TfedIAdBMU55QN7z+YCrMh+eArG6aWkFIwfQs8ejwrbt66xieGLAh6geDZ8H1x/cbVejaUPvjKhk0lNLNgpTIn+8YPxMnRY8iCoKegeB85eZTjnzzwmQ1TSUjWV+eDLHhr4ks8C4KeQ4+U3rh5lT0gH3wN0DSU0M6CD+emxYcfjcqTQVcU9B79Mu6pF+g7GzaV0MyCNCAzMNjf+WmJgf2ir2+/KJaL7nrZNdjfqB6ADsBxP1AU9+7f8ZoNG0poZsG5uRlx7pOPOAu6TtArC6/FttgQtSTJVjaFEJtiBRICxejYMWf5seND4sjQgLOuHSj+P5YekA80ee8jGyZKaGZBGpadunubT2BHJuebSQiAYlDGyPUbV8Ti4gtx6fJnkbpTp0fEi5fPOIZ9iUjxXyzuE1NTk+yFj2yYKCHZbS5R+/zieT64t2dB7nK+J7uViqIUXEunJYxsY3Q/k7qrZfnwXHxP9Mnuqtl2UXYh9DalUr2c6CupunKwT9HYt68kr1WVB9tbx7SuIWxLQuehyyPXBrxy+MhB8ddv/ix+/HFZLNcWxRdXLnL58RPD4h9Pv+fyly//KU6MDMf2bQc9QDM+fs7bUjanhDoLUqol22dmH4jh4bLoL3nKghS8lZ+kaMZr+ydRkcHK9UrC5Sr9q1/ysw7mpExZrog1ucNGbVl2VvVrW7yuqv2kpFXawHht1HQd7SO3rdWPuf36sZTIbEsek8RMuIZN2RZLKkVeru9EDYl5+1yBN4aGB8Uf//QHFm5p+V9ieuauePbs7/z5+Ytn4uzHp537tQt5cGRokL3Qk/dZsqFTwnoWDJaoXbl6me13nVA7lOaD4N1cqQdm8Ji3HAQxSyZfv66JBRW8CySPFLVKWa2JhObzIrcrJajS53JVrL2x29R1SrZtVf9Ey6jaon1p87UK7xtcw7ZYexK0NfBkLTgnyoYrG/V26TgrtfCYoDOQFN//8C2Lp6Gu6MjJD5zbZ4V8oKwbTN5ny4YxCe0s+GD6rhj+wO8SNc5Gm7VoOQc9dUFlsLokK9c4U60tJNTzNoGEptyxbXlkVXUTOZOpOpUJuX1uS0tXDdua58aX+X1wDUv1tiSU/TZXZKZk82XmVuVmdxh0jjNnxrhLqiWkEUzXdj6gbFgul8KlbFmeDRMlpEbJ8hs3r/HDqM95QYpRnVFCtASUWZwSVsTr7YwSkoA1maUirwQJJTWWqv7ZlJA9c7xCacMNZBe3AhE7jR6EIfm0iNQ1tQdrfBE8G+7nQaGsS9kiEpKA1IielqDJ+bFTJ7xmQYK7gTKLRAcylqQOG0HXT4ujn7/CeoekanCEg7yJhCXVTdRdw6BL2Z6EdA30zOiSqyTvV1jOGT7aLvCLPQhzfvyM+Nu3fwmF1IM1viEvxk4dZ0+yTN7HJNRZkFL5xMQN7vt6Xx3Dz08ynmvRrpx4o7qoLA5lFRoYSapX8vB7FeRNJNTy6zYr9LlNCYNrCLKcbk+Pni6sbRjlS/UMr9oB/qCph++++4aFMwdhzMEamr4YGzse2zcr5AWJeGvieqbJ+1BCOwvSZOTY6ROccr1LSCgRw5cWLKzbFGssiXoZgzQD84FYnDWVDBzk9Bz3qyWhaisYXKHnyvpr+w3pYdZFZVl5E22LJTbPM9YnVW1Z5ZHzAd4h8Z4+/SE2CKMHayZvT0TKfUJL2UZGsy3sjkhoZkFamjO4E0vU2qBIz3VGtxIAynyucsqU5UP9zjofsB/y0WPyzkTb2ZAljGRBmpyXWfACTc57nJbwgZ4Ap66pOWoJQJ6QJ+fHzwZL2drIhqGEOgvScCtlQerr7rYsSN1DfpldUwByhjwhX+7eu9PWdAVLSNZGlqhdCLJgR54FAegygumKfWL800/Yn1Yn7ws6C1IKJYvpr0odPXrY+7QEAN0MTd7TohYaoGk1GxbqWTCYnL/65W+RBQFoEZ0Nr13/QmVDKWHKbMgS6ixIP9qlvyqFLAhA65A35UMlMTN7n30ir9Jkw4IekKHhVVqi1rF5QQC6HM6GxX3iyrXL3KvkLmmKbFjQWZD/fsyHozz56DoAAKA55M/oWLCUTWdDkrBRNizoLHhnapItRhYEoH10Npy6O5l68r7AC7UfTovTp0e4K+pqGACQHno2HBs7kXopW4FsnZr6Hf82ajcuUQNgr6E9mrx9K1U2LNBSm88vjIsDxd/EGgMAtAf5NP7pudhSNqeE9AB5eGiQJxtdjQEAWod8OjxU5sUvzQZoCmfPHBPNcB3kl1/ehrjqAQDpgIQA5AwkBCBn9ryE1dW34t27/4r1pS74adPSz+Ld1qvwTyWC3iCzhP/+339Yggjrz537dIIdl5BEkcfbWp0Ly/gcfFwzJOxJvGXCxfWdlS83WJS3YsuQBRKCLHRWwvJzsf7uZ7FYfSW2dJbUQVaeE6tb0YwSK+P91X7mvrG6t2K16ghclbU0kWOZ5yRJnUmVKKvyevU+poR0HyLHMcWi9+tyX3mNfM5L6hzMevl+UWX32Dmr+6PrIveb7wfdB3Mbee8h9K5nByQ0gkF9jgRvTCwlVExIFVzOYzgkZAET5LTOIxAyYVsbLRXto86lJQnVcfl+8X0xzl/Vh9donVfkHjf4wuLrsuvBrmUHJIwGdyRI7XoKQt0GB6T1Tc5BaZU5jtE0AM3jKGLyJEH7slR0jOC4LUmo3ofb2RLqbWlf8zp4O+vaze25Pnpsb91k0FHyldD6TO/D7GQHJFFNK2EQkGFbFhycKmuYmOeViCUV7dMxCc32+Nrj5xxu77oPYE+Qu4T1wKNtDcGo3PXN30ImbChhuxnCFEWd82qHMyFfR9XxBWTiug9gT5C/hCqQF2UAxsuNbZO6mAnBF2S7hKDlgE6WtCGWKHScLdktNSUM74M6TtsS0md9Der6E788Eu4D2P1klrDhPKEjMGISSgJhHAGkRIy1S3CAGnVMtI2g3Xp95LhakJCUAWyLotuJXLNuM/hyaUnCcF+1vz4Ot61ENLYJrwkS7lm8ZUIAQHtAQgByBhICkDMFV2EaICEAfoCEAOQMJAQgZ9qWEADgh2wSxubaJEmTyUlwGwmT6gD0AB4kNCaI9UR1KyJCQtDj+JXQVZa06sUuDzH3tVaItJplAdgD+JdQyaXXZS6uG1nOqmMaZMLIOsyktaMA7HE6IGEgS9Li6Nja0SQJWVir3F63CUAX0PFM6FponUpCLo/ux0BC0GX4l5ClU2VKJDMrps6ESeUAdBl+JVTShZLZ9SorRiR0PSdyeZPfzwHQJXiQMNpdtGXiwRVdL7uS9FfKIhISkS6rIW2j388B0CVkkxAAkBlICEDOQEIAcgYSApAzkBCAnIGEAOQMJAQgZyAhADnjR0K16iXxL17nRGyJHAC7ED8S0oqX9ecc9Em/nsgDSAj2Al4kDINdyajL+f9pWH1Vz5J6eZq1jbksLZTY8ZMo3lbvq45l7q+Fs9sMMY4LwG4hu4TcFTV/NVHvkgYyUJ1aA0o/QzK3YSmNLix/Vm2lkdAUy25LgkwI9gLZJaTg17/xs8QJpTHLQwmDMluSUJw0Epq/LTS/DNT2kBDsBTJLaAe6KUoaCU3JCEgIeo1sEoajojZBt7DlTGiWQULQI2STMBSqHvhaTJKnsYSq3tzffK6zJeU6KXgLEnL75jYA7EIySRjJTAaUgai8mYRhG2EGjUoUbKvqpEyL5vFSSKiPG7bvOFcA8ib7wAwAIBOQEICcgYQA5AwkBCBnICEAOQMJAcgZSAhAzkBCAHIGEgKQM5AQgJyBhADkDCQEIGcgIQA5AwkByBlICEDOQEIAcgYSApAzkBCAnIGEAOTKAfF/HUoxqltHWt8AAAAASUVORK5CYII=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0bqimD0R-b-"
   },
   "source": [
    "You will also need to create a obj.data file and fill it in like this(change your class number accordingly. \n",
    "\n",
    "This backup path is where we will save the weights to of our model throughout training.\n",
    "\n",
    "Upload obj.names and obj.data in data subfolder of darknet\n",
    "\n",
    "\n",
    "\n",
    "![objdata.PNG](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ds7FpTfxVBfo"
   },
   "source": [
    "## 3) Generating train.txt and test.txt\n",
    "\n",
    "The last configuration files needed before we can begin to train our custom detector are the train.txt and test.txt files which will have paths to all our training images and valdidation images.\n",
    "\n",
    "To create the same we will be using two script for generating train and text text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lTrFVlcXT9c"
   },
   "outputs": [],
   "source": [
    "!python /content/generate_train.py\n",
    "!python /content/generate_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6jUj8WOXidO",
    "outputId": "77339d0f-8416-4c28-ad51-8ef33c600cf7"
   },
   "outputs": [],
   "source": [
    "# verifying if train.txt and test.txt can be seen in our darknet/data folder\n",
    "!ls /content/darknet/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93T4pvvUYJ-W"
   },
   "source": [
    "# Step 4: Download pre-trained weights for the convolutional layers.\n",
    "\n",
    "This step downloads the weights for the convolutional layers of the YOLOv4 network. By using these weights it helps your custom object detector to be way more accurate and not have to train as long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "leU-kM6WYYEh",
    "outputId": "cb985afd-7d39-41f6-d9d3-27567e9a2464"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNIvpcwKYvo8"
   },
   "source": [
    "# Step 5: Training  Your Custom Object Detector!\n",
    "\n",
    "We are now ready to train our custom YOLOv4 object detector on Amount,Invoice Number and Date classes. So run the following command.( -dont_show flag stops chart from popping up since Colab Notebook can't open images on the spot,\n",
    "-map flag overlays mean average precision on chart to see the accuracy)\n",
    "\n",
    "\n",
    "```\n",
    "!./darknet detector train <path to obj.data> <path to custom config> yolov4.conv.137 -dont_show -map\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xV0jeqiBYfu3",
    "outputId": "53c5a911-0e19-4d7e-a950-4e4d757c97e6"
   },
   "outputs": [],
   "source": [
    "!./darknet detector train data/obj.data cfg/yolov4-obj.cfg yolov4.conv.137 -dont_show -map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srhU2EJzd4H5"
   },
   "outputs": [],
   "source": [
    "# show chart.png of how custom object detector did with training\n",
    "imShow('chart.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJJoZNaweFK9"
   },
   "source": [
    "If for some reason you get an error or your Colab goes idle during training, you have not lost your partially trained model and weights because every 100 iterations a weights file called **yolov4-obj_last.weights** is saved to **content/backup/** folder.\n",
    "\n",
    "We can kick off training from our last saved weights file so that we don't have to restart!\n",
    "\n",
    "Just run the following command but with your backup location.\n",
    "\n",
    "\n",
    "```\n",
    "!./darknet detector train data/obj.data cfg/yolov4-obj.cfg /content/backup/yolov4-obj_last.weights -dont_show\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGaAjALwewaB"
   },
   "source": [
    "# Step 6: Checking the Mean Average Precision (mAP) of Your Model\n",
    "\n",
    "If you didn't run the training with the '-map- flag added then you can still find out the mAP of your model after training. Run the following command on any of the saved weights from the training to see the mAP value for that specific weight's file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4FbCzT3e7Eq"
   },
   "outputs": [],
   "source": [
    "!./darknet detector map data/obj.data cfg/yolov4-obj.cfg /content/backup/yolov4-obj_last.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljbkHgPPfEfL"
   },
   "source": [
    "# Step 7: Run Your Custom Object Detector!!!\n",
    "You have done it! You now have a custom object detector to make your very own detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e16DUDqAvULO",
    "outputId": "6d24cf41-475e-453e-95ff-6af8d64376bf"
   },
   "outputs": [],
   "source": [
    "# need to set our custom cfg to test mode \n",
    "%cd cfg\n",
    "!sed -i 's/batch=64/batch=1/' yolov4-obj.cfg\n",
    "!sed -i 's/subdivisions=16/subdivisions=1/' yolov4-obj.cfg\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hULtEhaWfQlK"
   },
   "source": [
    "Run your custom detector with this command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_tDxjEMFqjoN",
    "outputId": "90a64e47-af78-4ddb-856a-282c51944d70"
   },
   "outputs": [],
   "source": [
    "!./darknet detector test data/obj.data cfg/yolov4-obj.cfg /content/drive/MyDrive/yolov4-obj_best.weights /content/images/basic-invoice.png -thresh 0.4\n",
    "imShow('predictions.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmGxG247ff3j"
   },
   "source": [
    "# Step 9: Multiple Images at Once\n",
    "YOLOv4 object detections can be run on multiple images at once. This is done through having a text file which has the paths to several images that you want to have the detector run on.\n",
    "\n",
    "So we will be creating a images.txt file for the same and uploading it here\n",
    "\n",
    "\n",
    "\n",
    "![image.PNG](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCpuEQD1jfc6"
   },
   "source": [
    "## Save Results to .JSON File\n",
    "Here is an example of saving the multiple image detections to a .JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bMopxPVMjuD-",
    "outputId": "f1ecd1f5-38df-4252-922f-9d60cbd89682"
   },
   "outputs": [],
   "source": [
    "!./darknet detector test data/obj.data cfg/yolov4-obj.cfg /content/drive/MyDrive/yolov4-obj_best.weights -dont_show -out /content/result.json < /content/images.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xTcgmFjmu6t"
   },
   "source": [
    "## Using result.json to crop the bounding box of the predicted classes of each images from images folder which we will pass to pytesseract for image to text conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UYG5qnjm6Jx",
    "outputId": "a33650d5-4b2f-45d1-dacd-7ee2ee8a5384"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "\n",
    "#Reading json file which contains details of detected classes\n",
    "with open('/content/result.json', 'r') as j:\n",
    "    contents = json.loads(j.read())\n",
    "    \n",
    "bb=dict()\n",
    "count = 0\n",
    "\n",
    "#Looping for reading and cropping the detected classes based on their coordinates value which is stored in result.json\n",
    "\n",
    "for i in contents:\n",
    "    im = cv2.imread('/content/images/'+ i['filename'][16:])\n",
    "    print('/content/images/'+ i['filename'][16:])\n",
    "    for obj in i['objects']:\n",
    "        if obj['name']=='Amount':\n",
    "            bb=obj['relative_coordinates']\n",
    "            x = int((bb['center_x'] - bb['width']/2) * im.shape[1])\n",
    "            y = int((bb['center_y'] - bb['height']/2) * im.shape[0])\n",
    "            w = int(bb['width'] * im.shape[1])\n",
    "            h = int(bb['height'] * im.shape[0])\n",
    "            cropped = im[y:y+h,x:x+w]\n",
    "            cv2.imwrite('/content/images/'+'Amount_'+i['filename'][16:],cropped)\n",
    "            \n",
    "        elif obj['name']=='Invoice Number':\n",
    "            bb=obj['relative_coordinates']\n",
    "            x = int((bb['center_x'] - bb['width']/2) * im.shape[1])\n",
    "            y = int((bb['center_y'] - bb['height']/2) * im.shape[0])\n",
    "            w = int(bb['width'] * im.shape[1])\n",
    "            h = int(bb['height'] * im.shape[0])\n",
    "            cropped = im[y:y+h,x:x+w]\n",
    "            print('/content/images/'+'Invoice Number_'+i['filename'][16:])\n",
    "            cv2.imwrite('/content/images/'+'Invoice Number_'+ i['filename'][16:],cropped)\n",
    "            \n",
    "        elif obj['name']=='Date':\n",
    "            bb=obj['relative_coordinates']\n",
    "            x = int((bb['center_x'] - bb['width']/2) * im.shape[1])\n",
    "            y = int((bb['center_y'] - bb['height']/2) * im.shape[0])\n",
    "            w = int(bb['width'] * im.shape[1])\n",
    "            h = int(bb['height'] * im.shape[0])\n",
    "            cropped = im[y:y+h,x:x+w]\n",
    "            cv2.imwrite('/content/images/'+'Date_'+i['filename'][16:],cropped)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sxYcjsJnPka"
   },
   "source": [
    "Now passing we will be passing all the cropped predicted classes of each images into pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Jtx9tIuW-HE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CLASS_DETECTION_INVOICE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
